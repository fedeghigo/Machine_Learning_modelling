{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione di vini attraverso gaussiane multivariate\n",
    "<img src=\"img/wine.jpg\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo quaderno riprendiamo la classificazione dei vini, utilizzando l'intero insieme delle 13 feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Caricamento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come al solito, iniziamo caricando il dataset. \n",
    "\n",
    "Ricordiamo che vi sono 178 osservazioni, ognuna con 13 feature ed una etichetta (1, 2, 3). Come prima, le divideremo in un training set di 130 osservazioni ed un test set di 48 osservazioni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Modulo utile per gestire distribuzioni gaussiane\n",
    "from scipy.stats import norm, multivariate_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carichiamo il dataset\n",
    "data = np.loadtxt('data/wine.data.txt', delimiter=',')\n",
    "# Nomi delle feature\n",
    "featurenames = ['Alcool', 'Acido malico', 'Ceneri', 'Alcalinità delle ceneri', 'Magnesio', 'Fenoli totali', \n",
    "               'Flavonoidi', 'Fenoli non flavonoidi', 'Proantocianina', 'Intensità di colore', 'Tonalità',\n",
    "              'OD280/OD315', 'Prolina']\n",
    "# Suddividiamo le 178 istanze in un training set (trainx, trainy) di taglia 130 e un test set (testx, testy) di taglia 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit di un modello generativo gaussiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo ora una funzione che fa il fit di un modello generativo gaussiano. \n",
    "Per ogni classe (`j=1,2,3`), abbiamo:  \n",
    "* `pi[j]`: il peso relativo della classe\n",
    "* `mu[j,:]`: la media, un vettore 13-dimensionale\n",
    "* `sigma[j,:,:]`: la matrice di covarianza 13x13\n",
    "\n",
    "Ciò significa che `pi` sarà un array 4 $\\times$ 1 (gli array Python sono numerati dall'indice 0, e noi lasceremo `j=0` inutilizzato), `mu` sarà un array 4 $\\times$ 13 e `sigma` sarà un array 4 $\\times$ 13 $\\times$ 13. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 3  # numero di classi (etichette 1,2,...,k)\n",
    "    d = (x.shape)[1]  # numero di feature\n",
    "    mu = np.zeros((k+1,d))\n",
    "    sigma = np.zeros((k+1,d,d))\n",
    "    pi = np.zeros(k+1)\n",
    "    for j in range(1,k+1):\n",
    "        indices = (y == j) # vettore rappresentante il sottoinsieme degli esempi di classe j\n",
    "        mu[j] = np.mean(x[indices,:], axis=0) # axis=0 indica che la media è ottenuta aggregando le righe, \n",
    "                                                    # ovvero colonna per colonna\n",
    "        sigma[j] = np.cov(x[indices,:], rowvar=0, bias=1) # rowvar=0 indica che la matrice x contiene\n",
    "                                                # le osservazioni sulle righe e le feature sulle colonne;\n",
    "                                                # bias=1 corrisponde alla normalizzazione vista a lezione\n",
    "        pi[j] = float(sum(indices))/float(len(y)) # = frazione degli esempi di tipo label su tutti gli esempi\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit di un modello generativo gaussiano sui dati di training\n",
    "mu, sigma, pi = fit_generative_model(trainx, trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predizione delle etichette per gli esempi di test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio da svolgere**</font>: Vogliamo definire una routine di testing generale che riceva in input:\n",
    "* gli array `pi`, `mu`, `sigma` che definiscono il modello generativo, come costruiti nella precedente sezione\n",
    "* un test set (una matrice di input `tx` e le corrispondenti etichette `ty`)\n",
    "* una lista di feature `features` (scelte nell'intervallo 0-12)\n",
    "\n",
    "La routine deve restituire il numero di misclassificazioni del modello generativo sui dati di test, *quando il modello è costruito sulla base delle sole feature specificate*. Per esempio, usando solo le tre feature 2 (`'Ceneri'`), 4 (`'Magnesio'`) e 6 (`'Flavonoidi'`) si ottengono 7 misclassificazioni (su 48 esempi di test), quindi\n",
    "\n",
    "        test_model(mu, sigma, pi, [2,4,6], testx, testy)\n",
    "\n",
    "dovrebbe stampare `7/48`.\n",
    "\n",
    "Per restringere l'attenzione ad un sottoinsieme di feature, scegliamo le corrispondenti coordinate del vettore 13-dimensionale delle medie e una sottomatrice opportuna della matrice di covarianza 13 $\\times$ 13. Sfruttiamo la notazione NumPy `sigma[j][R, C]` dove $R=[r_1,\\ldots,r_k]$ e $C=[c_1,\\ldots,c_k]$ sono due liste di indici; questo restituisce un vettore NumPy contenente i valori $\\Sigma^{(j)}_{r_1,c_1}, \\ldots, \\Sigma^{(j)}_{r_k,c_k}$. Poi riformattiamo questo vettore in forma di matrice $k \\times k$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23325279, -0.31359816],\n",
       "       [-0.31359816,  6.04011898]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esempio di estrazione della sottomatrice di sigma[1] formata dalle feature 0 e 3\n",
    "sigma[1][[0,0,3,3], [0,3,0,3]].reshape(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente implementazione manca solo dell'istruzione che calcola il discriminante $\\delta_j(x)$. Per completare l'implementazione può essere utile ricorrere anche al metodo `multivariate_normal.logpdf` importato da SciPy (si consulti la documentazione SciPy per la sintassi e i parametri del metodo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa la performance di un modello gaussiano costruito sulla base di un sottoinsieme delle feature\n",
    "def test_model(mu, sigma, pi, features, tx, ty):\n",
    "    k = 3 # 3 classi\n",
    "    mistakes = 0\n",
    "    for i in range(len(tx)): # ciclo sugli esempi del test set\n",
    "        x = tx[i] # input i-esimo\n",
    "        y = ty[i] # output i-esimo\n",
    "        # Ricerca del massimo discriminante: argmax_j delta_j(x)\n",
    "        delta_best = -np.inf # valore massimo del discriminante trovato sinora (inizialmente è -INFINITO)\n",
    "        best = None # indice corrispondente\n",
    "        for j in range(1,k+1):\n",
    "            mu_j = mu[j, features]\n",
    "            rows = [f_row for f_row in features for f_col in features]\n",
    "            cols = [f_col for f_row in features for f_col in features]\n",
    "            sigma_j = sigma[j][rows, cols].reshape((len(features), len(features)))\n",
    "            ### Inserire qui l'istruzione appropriata per il calcolo del discriminante: \n",
    "            # delta_j = ...\n",
    "            ###\n",
    "            # Aggiornamento del discriminante massimo\n",
    "            if delta_j > delta_best:\n",
    "                delta_best = delta_j\n",
    "                best = j\n",
    "        if y != best: mistakes += 1\n",
    "    print(mistakes, '/', len(tx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la soluzione.\n",
    "<!--\n",
    "            delta_j = np.log(pi[j]) + multivariate_normal.logpdf(x[features], mean=mu_j, cov=sigma_j)\n",
    "            # NB. Una soluzione alternativa equivalente è: \n",
    "            delta_j = np.log(pi[j]) + np.log(multivariate_normal.pdf(x[features], mean=mu_j, cov=sigma_j)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiamo la procedura sull'insieme di feature 2 (Ceneri), 4 (Magnesio), e 6 (Flavonoidi). Si dovrebbero ottenere 7 errori su 48. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 / 48\n"
     ]
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [2, 4, 6], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizi rapidi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio 1**. Quante misclassificazioni si hanno sul test set utilizzando solamente la feature 2 (Ceneri)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la risposta.\n",
    "<!--\n",
    "test_model(mu, sigma, pi, [2], testx, testy) \n",
    "# la risposta è 29 / 48\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio 2**. Quante misclassificazioni si hanno utilizzando le feature 0 (Alcool) e 2 (Ceneri)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la risposta.\n",
    "<!--\n",
    "test_model(mu, sigma, pi, [0,2], testx, testy)\n",
    "# la risposta è 12 / 48\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio 3**. Quante misclassificazioni si hanno utilizzando le feature 0 (Alcool), 2 (Ceneri), e 6 (Flavonoidi)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la risposta. \n",
    "<!--\n",
    "test_model(mu, sigma, pi, [0,2,6], testx, testy)\n",
    "# la risposta è 3 / 48\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio 4**. Quante misclassificazioni si hanno utilizzando tutte e 13 le feature? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la risposta. \n",
    "<!--\n",
    "test_model(mu, sigma, pi, range(0,13), testx, testy)\n",
    "# la risposta è 2 / 48\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Esercizio 5**. A lezione, abbiamo ottenuto delle risposte lievemente diverse ad alcune di queste domande. Quale potrebbe essere il motivo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la risposta. \n",
    "<!--\n",
    "Il generatore pseudocasuale utilizzato per partizionare gli esempi in training e test è stato inizializzato in modo diverso, risultando così in un modello generativo con diversi parametri e in un test set diverso. \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
