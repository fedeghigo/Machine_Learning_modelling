{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificazione di vini attraverso gaussiane unidimensionali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/wine.jpg\" width=\"30%\"/>\n",
    "\n",
    "Il dataset **Wine** sarà il nostro esempio ricorrente per la discussione dell' *approccio generativo alla classificazione*. \n",
    "\n",
    "Il dataset (costruito nel 1991 dall'Università di Genova) può essere scaricato dal repository UCI (https://archive.ics.uci.edu/ml/datasets/wine). \n",
    "Contiene 178 osservazioni, ognuna corrispondente ad una bottiglia di vino: \n",
    "* Le feature (`x`): un vettore 13-dimensionale consistente di caratteristiche chimiche e visuali della bottiglia di vino\n",
    "* Le etichette (`y`): la cantina di provenienza della bottiglia (1,2,3)\n",
    "\n",
    "Prima di continuare, assicurarsi che il dataset (`wine.data.txt`) sia presente in una sottocartella di nome `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Caricamento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniziamo caricando i pacchetti Python che useremo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Un modulo utile per la gestione di distribuzioni gaussiane\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "# Moduli per la visualizzazione di grafici interattivi\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora carichiamo il dataset Wine. Ci sono 178 osservazioni, ciascuna con 13 feature ed un'etichetta (1,2,3). \n",
    "Le divideremo in un training set di 130 punti ed un test set di 48 punti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/wine.data.txt', delimiter=',')\n",
    "# Nomi delle feature\n",
    "featurenames = ['Alcool', 'Acido malico', 'Ceneri', 'Alcalinità delle ceneri', 'Magnesio', 'Fenoli totali', \n",
    "               'Flavonoidi', 'Fenoli non flavonoidi', 'Proantocianina', 'Intensità di colore', 'Tonalità',\n",
    "              'OD280/OD315', 'Prolina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fissiamo una particulare permutazione pseudocasuale dei dati, ed usiamola per effettuare la partizione in training e test.\n",
    "Vogliamo creare 4 array:\n",
    "* `trainx`: 130x13, le osservazioni di training\n",
    "* `trainy`: 130x1, le etichette delle osservazioni di training\n",
    "* `testx`: 48x13, le osservazioni di test\n",
    "* `testy`: 48x1, le etichette delle osservazioni di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suddividiamo le 178 istanze in un training set (trainx, trainy) di taglia 130 e un test set (testx, testy) di taglia 48\n",
    "# Separiamo inoltre i dati di input (colonne 1-13) dalle etichette (colonna 0)\n",
    "np.random.seed(0) # inizializzazione del generatore pseudo-casuale (per la riproducibilità degli esperimenti)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo quanti dati di training ci sono in ogni classe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 54, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainy==1), sum(trainy==2), sum(trainy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio rapido 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quante istanze di test sono presenti in ciascuna classe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 17, 15)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testy==1), sum(testy==2), sum(testy==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\finnocenti\\AppData\\Local\\Temp\\ipykernel_15688\\2342593116.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  print(len([x for x in testy[[testy==x]]]))\n"
     ]
    }
   ],
   "source": [
    "# modificate questa cella\n",
    "for x in range(1,4):\n",
    "    print(len([x for x in testy[[testy==x]]]))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la soluzione. \n",
    "<!--\n",
    "sum(testy==1), sum(testy==2), sum(testy==3)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Costruzione della distribuzione di una singola feature da ognuna delle cantine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focalizziamoci su una singola feature: 'Alcool'. Questa è la prima feature, quella di indice 0. Il seguente grafico è un'*istogramma* dei valori di questa feature nella classe 1 (cantina 1), insieme al *fit gaussiano* della distribuzione. \n",
    "\n",
    "<img src=\"img/wine_histogram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può generare un grafico di questo tipo? \n",
    "\n",
    "La seguente funzione, **density_plot**, lo fa per ogni feature ed etichetta. La prima riga aggiunge una componente interattiva che ci permette di scegliere questi parametri utilizzando dei controlli. \n",
    "\n",
    "Provatelo, e poi, osservate il codice attentamente per capire esattamente ciò che fa ciascuna riga della funzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d1ea3154ac49c5a17b9e0d265b814c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature', max=12), IntSlider(value=1, description='label…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12), label=IntSlider(1,1,3))\n",
    "def density_plot(feature, label):\n",
    "    plt.hist(trainx[trainy==label,feature], density=True)\n",
    "    #\n",
    "    mu = np.mean(trainx[trainy==label,feature]) # media\n",
    "    var = np.var(trainx[trainy==label,feature]) # varianza\n",
    "    std = np.sqrt(var) # deviazione standard\n",
    "    #\n",
    "    x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n",
    "    plt.title(\"Cantina \"+str(label) )\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Densità', fontsize=14, color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio rapido 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domanda: per quale feature (indice da 0 a 12) la distribuzione dei valori (nel training set) della Cantina 1 ha la deviazione standard *minima*? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.82962509e-01 6.56756786e-01 1.91767278e-01 2.45766535e+00\n",
      " 1.08840191e+01 3.43734147e-01 3.90396479e-01 5.96428889e-02\n",
      " 4.53274368e-01 1.22463376e+00 1.15433202e-01 3.55846328e-01\n",
      " 2.20103973e+02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.zeros(13)\n",
    "for feature in range(0,13):\n",
    "    std[feature] = np.sqrt(np.var(trainx[trainy==1,feature]))\n",
    "print(std)\n",
    "np.argmin(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Tempo (secondi):  0.0038461685180664062\n"
     ]
    }
   ],
   "source": [
    "t_before = time.time()\n",
    "std=np.zeros(13)\n",
    "for i in range(0,13):\n",
    "    std[i]=np.sqrt([np.var(trainx[trainy==1,i])])\n",
    "print(np.argmin(std))\n",
    "t_after = time.time()\n",
    "print(\"Tempo (secondi): \", t_after - t_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Tempo (secondi):  0.018377304077148438\n"
     ]
    }
   ],
   "source": [
    "t_before = time.time()\n",
    "std=pd.DataFrame()\n",
    "for i in range(0,13):\n",
    "    std[i]=np.sqrt([np.var(trainx[trainy==1,i])])\n",
    "print(np.argmin(std))\n",
    "t_after = time.time()\n",
    "print(\"Tempo (secondi): \", t_after - t_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Tempo (secondi):  0.0020275115966796875\n"
     ]
    }
   ],
   "source": [
    "# modificate questa cella\n",
    "t_before = time.time()\n",
    "var=[]\n",
    "for x in range(0,13):\n",
    "    var_temp= np.sqrt([np.var(trainx[trainy==1,x])])\n",
    "    var.append(var_temp)\n",
    "    \n",
    "print(np.argmin(var))\n",
    "t_after = time.time()\n",
    "print(\"Tempo (secondi): \", t_after - t_before)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per la soluzione. \n",
    "<!--\n",
    "std = np.zeros(13)\n",
    "for feature in range(0,13):\n",
    "    std[feature] = np.sqrt(np.var(trainx[trainy==1,feature]))\n",
    "print(std)\n",
    "np.argmin(std)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit di una gaussiana per ogni classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo una funzione che effettua il fit di un modello generativo gaussiano alle tre classi, restringendosi ad un'unica feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La funzione assume che l'etichetta y vari nell'insieme {1,2,3}\n",
    "def fit_generative_model(x,y,feature):\n",
    "    k = 3 # numero di classi\n",
    "    mu = np.zeros(k+1) # lista delle medie\n",
    "    var = np.zeros(k+1) # lista delle varianze\n",
    "    pi = np.zeros(k+1) # vettore dei pesi delle classi\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label] = np.mean(x[indices,feature])\n",
    "        var[label] = np.var(x[indices,feature])\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, var, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiamiamo questa funzione sulla feature di indice 0 (Alcool). Quali sono i pesi delle classi? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 0 # 'alcool'\n",
    "mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "print(pi[1:])\n",
    "print(mu[1:])\n",
    "print(var[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafichiamo la distribuzione Gaussiana risultante per ciascuna delle tre classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def show_densities(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"Cantina \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Densità', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio rapido 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando il grafico interattivo soprastante, rispondere alle seguenti domande: \n",
    "* Per quale feature (0-12) le distribuzioni della classe 1 e 3 si *sovrappongono* di più? \n",
    "* Per quale feature (0-12) la classe 3 è quella con maggiore varianza rispetto alle altre due classi? \n",
    "* Per quale feature (0-12) le tre classi sembrano meglio *separate* (almeno ad occhio)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliccare **qui** per le risposte. \n",
    "<!--\n",
    "* Feature 2 (Ceneri)\n",
    "* Feature 9 (Intensità di colore)\n",
    "* Feature 6 (Flavonoidi)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predizione delle etichette sul test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto accuratamente possiamo predire la classe (1,2,3) sulla base di una singola feature? Il codice sottostante ci consente di scoprirlo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact( feature=IntSlider(0,0,12) )\n",
    "def test_model(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    k = 3 # Etichette 1,2,...,k\n",
    "    n_test = len(testy) # Numero di osservazioni di test\n",
    "    score = np.zeros((n_test,k+1))\n",
    "    for i in range(0,n_test):\n",
    "        for label in range(1,k+1):\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(testx[i,feature], mu[label], np.sqrt(var[label]))\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Conteggiamo il numero di predizioni errate\n",
    "    errors = np.sum(predictions != testy)\n",
    "    print(\"Errori di test sulla base della feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo quaderno, abbiamo considerato classificatori che usano solo una delle 13 possibili feature. La scelta di un sottoinsieme di feature è detta **feature selection**. In generale, questa scelta va operata sulla base del *training set* (o meglio, sulla base di un apposito *validation set*) -- in particolare, senza considerare il *test set*. \n",
    "\n",
    "Per i dati sul vino, calcolate l'errore di training e l'errore di test associato con ogni possibile scelta di una feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scrivete il vostro codice qui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sulla base dei vostri risultati, rispondere alle seguenti domande: \n",
    "* Quali tre feature hanno l'errore più basso sul training set? \n",
    "* Quali tre feature hanno l'errore più basso sul test set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
